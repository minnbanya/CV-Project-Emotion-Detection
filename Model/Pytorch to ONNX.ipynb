{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78533229-acfb-4b3d-ac4b-36839c164656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)  # Dropout after conv1\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.dropout2 = nn.Dropout2d(0.2)  # Dropout after conv2\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(512)\n",
    "        self.dropout3 = nn.Dropout2d(0.25)  # Dropout after conv3\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.dropout4 = nn.Dropout2d(0.25)  # Dropout after conv4\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(512 * 3 * 3, 256)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(256)\n",
    "        self.dropout_fc1 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(512)\n",
    "        self.dropout_fc2 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 7)  # 7 output classes (emotions)\n",
    "        \n",
    "        # Xavier initialization\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First Conv Layer\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)  # 48x48 -> 24x24\n",
    "        x = self.dropout1(x)  # Apply dropout\n",
    "        \n",
    "        # Second Conv Layer\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)  # 24x24 -> 12x12\n",
    "        x = self.dropout2(x)  # Apply dropout\n",
    "        \n",
    "        # Third Conv Layer\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)  # 12x12 -> 6x6\n",
    "        x = self.dropout3(x)  # Apply dropout\n",
    "        \n",
    "        # Fourth Conv Layer\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.max_pool2d(x, 2)  # 6x6 -> 3x3\n",
    "        x = self.dropout4(x)  # Apply dropout\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor: 512 * 3 * 3\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.dropout_fc1(x)  # Apply dropout\n",
    "        \n",
    "        x = F.relu(self.bn_fc2(self.fc2(x)))\n",
    "        x = self.dropout_fc2(x)  # Apply dropout\n",
    "        \n",
    "        x = self.fc3(x)  # Output layer\n",
    "        \n",
    "        return x, F.log_softmax(x, dim=1)  # Raw logits, Log-Softmax for normalized probabilities\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d4668-7bb3-4ffa-91ac-3f5b6d27688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2478695/3603453630.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))  # Load state dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been exported to ./fer_cnn.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Recreate the model and load weights\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))  # Load state dict\n",
    "model.eval()  # Set to evaluation mode# Set the model to evaluation mode\n",
    "\n",
    "# Define a dummy input with the correct input size\n",
    "dummy_input = torch.randn(1, 1, 48, 48)  # Batch size=1, Channels=1, Height=48, Width=48\n",
    "\n",
    "# Export the model to ONNX format\n",
    "onnx_file_path = \"./fer_cnn.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,                           # The PyTorch model\n",
    "    dummy_input,                     # Example input\n",
    "    onnx_file_path,                  # File path to save the ONNX model\n",
    "    input_names=[\"input\"],           # Optional: Name the input tensor\n",
    "    output_names=[\"output\"],         # Optional: Name the output tensor\n",
    "    dynamic_axes={                   # Optional: Enable dynamic axes\n",
    "        \"input\": {0: \"batch_size\"},  # Dynamic batch size for input\n",
    "        \"output\": {0: \"batch_size\"}  # Dynamic batch size for output\n",
    "    },\n",
    "    opset_version=11                 # ONNX opset version\n",
    ")\n",
    "\n",
    "print(f\"Model has been exported to {onnx_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8375b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minnb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO\n",
    "from supervision import Detections\n",
    "from PIL import Image\n",
    "\n",
    "# download model\n",
    "model_path = \"model.pt\"\n",
    "\n",
    "# load model\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e00094-3d5c-42fa-a068-367c4e5060b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.38  Python-3.11.9 torch-2.1.0+cu121 CPU (12th Gen Intel Core(TM) i7-12650H)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'model.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
      "Collecting onnxruntime-gpu\n",
      "  Downloading onnxruntime_gpu-1.20.1-cp311-cp311-win_amd64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\minnb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\minnb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime-gpu) (24.3.25)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\minnb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime-gpu) (1.24.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\minnb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime-gpu) (23.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\minnb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime-gpu) (3.20.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\minnb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime-gpu) (1.12)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\minnb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\minnb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\minnb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime-gpu) (3.5.4)\n",
      "Downloading onnxruntime_gpu-1.20.1-cp311-cp311-win_amd64.whl (279.7 MB)\n",
      "   --------------------------------------- 279.7/279.7 MB 38.6 MB/s eta 0:00:00\n",
      "Installing collected packages: onnxruntime-gpu\n",
      "Successfully installed onnxruntime-gpu-1.20.1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  19.3s, installed 1 package: ['onnxruntime-gpu']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.42...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: FLOAT8E4M3FN\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  20.9s, saved as 'model.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (21.4s)\n",
      "Results saved to \u001b[1mC:\\Studies\\AIT\\3rd semester\\CV\\CV-Project-Emotion-Detection\\Model\u001b[0m\n",
      "Predict:         yolo predict task=detect model=model.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=model.onnx imgsz=640 data=data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Model has been exported to ONNX format.\n"
     ]
    }
   ],
   "source": [
    "# Export the model to ONNX format\n",
    "model.export(format=\"onnx\")\n",
    "\n",
    "print(\"Model has been exported to ONNX format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabb3e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'FACE'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbbfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
